sampler:
  type: Grid
  bounds: [[1, 3], [1, 3]]
  num_samples: 3
  parameters: ['m', 'n']

executor:
  type: DaskExecutorSimulationPipeline
  base_run_dir: /path/to/simplePipeline
  base_out_dir: None
  # This must have 'executor' in the key_name and an integer that corresponds to the order in the pipeline.
  executor_simulation_1:
    type: DaskExecutorSimulation
    
    #not necessary as this will be defined by the highest level executor
    #base_run_dir: /project/project_462000451/test-enchanted/simple_1
    runner_return_path: /scratch/project_462000451/gene_out/enchanted_out/simple_test/runner_return

    runner:
      type: SIMPLErunner
      executable_path: /users/danieljordan/enchanted-surrogates/tests/automated_tests_no_HPC/simple/simple.sh
      other_params: {}
      
    worker_args: # to be specified for the SLURMCluster in DASK
      account: "project_462000451"
      queue: "small"
      cores: 1
      memory: "1GB"
      #Set the walltime for entire cluster to be able to run everything set in the sampler, taking into account the number of workers. 
      walltime: "00:10:00"
      interface: "nmn0"
      # The job script prologue is ran on every worker at start up
      job_script_prologue: # this is possibly dependent on which code you want
        - 'export PATH="/project/project_462000451/enchanted_container_lumi3/bin:$PATH"'
        # Change this for your own personal enchanted surrogates clone
        - 'cd /users/danieljordan/enchanted-surrogates/'
        # This command gives the worker access to the python within our container. 
        - 'export PYTHONPATH=$PYTHONPATH:/users/danieljordan/enchanted-surrogates/src' # NB: to use the enchanted-surrogate library
      # These are appended to the sbatch that requestes the resources for each worker.
      job_extra_directives:
        - '-o /scratch/project_462000451/gene_out/enchanted_out/simple_test/%x.%j.out'
        - '-e /scratch/project_462000451/gene_out/enchanted_out/simple_test/%x.%j.err'
    n_jobs: 2

  #This must have the string pipeline_parser in the key and an integer that corresponds to the order in the pipeline.
  pipeline_parser_1:
    function: simple_out_to_simple_in

  executor_simulation_2:
    type: DaskExecutorSimulation
    #not necessary as this will be defined by the highest level executor
    # base_run_dir: /project/project_462000451/test-enchanted/simple_2
    runner_return_path: /scratch/project_462000451/gene_out/enchanted_out/simple_test/runner_return

    runner:
      type: SIMPLErunner
      executable_path: /users/danieljordan/enchanted-surrogates/tests/automated_tests_no_HPC/simple/simple.sh
      other_params: {}
      

    worker_args: # to be specified for the SLURMCluster in DASK
      account: "project_462000451"
      queue: "small"
      cores: 1
      memory: "1GB"
      #Set the walltime for entire cluster to be able to run everything set in the sampler, taking into account the number of workers. 
      walltime: "00:10:00"
      interface: "nmn0"
      # The job script prologue is ran on every worker at start up
      job_script_prologue: # this is possibly dependent on which code you want
        - 'export PATH="/project/project_462000451/enchanted_container_lumi3/bin:$PATH"'
        # Change this for your own personal enchanted surrogates clone
        - 'cd /users/danieljordan/enchanted-surrogates/'
        # This command gives the worker access to the python within our container. 
        - 'export PYTHONPATH=$PYTHONPATH:/users/danieljordan/enchanted-surrogates/src' # NB: to use the enchanted-surrogate library
      # These are appended to the sbatch that requestes the resources for each worker.
      job_extra_directives:
        - '-o /scratch/project_462000451/gene_out/enchanted_out/simple_test/%x.%j.out'
        - '-e /scratch/project_462000451/gene_out/enchanted_out/simple_test/%x.%j.err'
    n_jobs: 2
