sampler:
  type: SpatiallyAdaptiveSparseGrids
  # parameters: [['box','kymin'],['box','x0']]
  # bounds: [[0.5,0.55],[0.9,0.91]]
  bounds: [[4,6.7], [2.1,3.5], [0.16,2.9]]
  parameters: ['omt1','omt2','omn']
  infer_bounds: False
  infer_parents: False
  initial_level: 1      

executor:
  type: DaskExecutorActive
  base_run_dir: /scratch/project_462000451/enchanted_test_out/sasg_GENE_test # Because the runner only executes a python function I do not need a run_base_dir
  # runner_return_path: /scratch/project_462000451/gene_out/enchanted_test_out/MMMG/runner_return
  runner_return_headder: '_grp_species_0-omt,_grp_species_1-omt,species-omn,growthrate'
  max_cycles: 2
  static_executor:
    type: DaskExecutorSimulation
    runner:
      type: GENErunner
      executable_path: /scratch/project_462000451/gene_enchanted/enchanted_executable/gene_lumi_csc
      return_mode: growthrate
      base_parameters_file_path: /users/danieljordan/base_parameters/parameters_base_uq_highprec
    worker_args: # to be specified for the SLURMCluster in DASK
      cores: 1
      memory: "240GB" # Memory on a lumi cpu node 256GB
      walltime: "12:00:00" #Max time limit of entire cluster
      job_extra_directives:
        - "--nodes 1"
        - "--partition standard"
        - "--account project_462000451"
        - "--ntasks 128"
        - '-o /scratch/project_462000451/enchanted_test_out/sasg_GENE_UQ_2/%x.%j.out'
        - '-e /scratch/project_462000451/enchanted_test_out/sasg_GENE_UQ_2/%x.%j.err'
      interface: "nmn0"
      # The job script prologue is ran on every worker at start up
      job_script_prologue: # this is possibly dependent on which code you want
        - echo "mem_per_cpu,mem_per_gpu,mem_per_node"
        - unset SLURM_MEM_PER_CPU #For some reason when running from sbatch this is being set and causing an error as is conflicts with mem_per_node
        - export LD_LIBRARY_PATH=/opt/cray/pe/papi/7.1.0.1/lib64:/opt/cray/libfabric/1.15.2.0/lib64:$LD_LIBRARY_PATH
        - echo $SLURM_MEM_PER_CPU
        - echo $SLURM_MEM_PER_GPU
        - echo $SLURM_MEM_PER_NODE
        - echo $SLURM_N
        - 'export PATH="/project/project_462000451/enchanted_container_lumi3/bin:$PATH"'
        # Change this for your own personal enchanted surrogates clone
        - 'cd /users/danieljordan/enchanted-surrogates2/'
        # This command gives the worker access to the python within our container. 
        - 'export PYTHONPATH=$PYTHONPATH:/users/danieljordan/enchanted-surrogates2/src' # NB: to use the enchanted-surrogate library
      # These are appended to the sbatch that requestes the resources for each worker.
    n_jobs: 10

# fatal: SLURM_MEM_PER_CPU, SLURM_MEM_PER_GPU, and SLURM_MEM_PER_NODE are mutually exclusive.

#when using sbatch
# mem_per_cpu,mem_per_gpu,mem_per_node
# 896

# 229376

# when using run.py
# mem_per_cpu,mem_per_gpu,mem_per_node


# 229376